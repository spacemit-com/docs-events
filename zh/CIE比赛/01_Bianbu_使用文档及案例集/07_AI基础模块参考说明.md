sidebar_position: 7

> 本文介绍进迭时空Demo Zoo的基础模块使用说明，可供开发者参考。

# 1. 环境安装

### 1.1 python环境依赖安装

设置python pip源：

```
pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
pip config set global.extra-index-url https://git.spacemit.com/api/v4/projects/33/packages/pypi/simple
```

创建虚拟环境：

```
python3 -m venv ~/demo-zoo-venv
source ~/demo-zoo-venv/bin/activate
```

在虚拟环境中安装python依赖：

```
pip install onnxruntime
pip install spacemit-ort
pip install opencv-python
pip install pillow
```

### 1.2 环境验证

```
source ~/demo-zoo-venv/bin/activate
pip list
```

输出如图所示：

![image-20250417165056076](images/demo-zoo-pip.png)

# 2. 下载模型仓库

（1）下载模型仓库压缩包：[demo_zoo.zip](code/spacemit_demo)

（2）下载之后解压：`unzip spacemit_demo.zip -d ~/spacemit_demo`

# 3. CV模块说明

## 3.1 图像分类

### 3.1.1 简介

图像分类（Image Classification）是计算机视觉领域中的一个基本问题，其目标是根据图像的内容给图像分配一个或多个预定义的类别标签。

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="images/classification_1.png">
    <br>
</center>

### 3.1.2 常见模型

常见的图像分类模型包括resnet50、vgg16等，进迭时空Demo Zoo提供多种分类模型，详见 [CV模型支持列表](https://active.spacemit.com/doc/RISC-V比赛/03_蓝桥杯比赛产品包/06_Demo%20Zoo#1.-CV模型列表)。

### 3.1.3 图像分类流程 

图像分类的一般流程如下图所示：

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="images/classification_2.png">
    <br>
</center>
- **预处理**：对输入图像进行标准化、调整大小、数据增强等操作，以便于输入到神经网络中，提升模型的训练效果和推理精度。
- **模型推理**：将预处理后的图像送入已经训练好的模型中，进行前向传播计算并输出预测结果。

### 3.1.4 API简介

我们对图像分类的关键步骤封装进行封装，用户只需调用封装后的API函数，即可快速达到处理目标。

#### 读取图像

读取图像的API函数如下，`image_path` 为具体的图片路径，可以是相对路径或者绝对路径。

```python
img = get_image(image_path)
```

#### 预处理

图像预处理的API函数如下，`img` 为调用 `get_image` 后的结果。

```python
img = preprocess(img)
```

#### 推理

模型推理的API函数如下，`model_path` 为模型路径，`img` 为调用预处理后的结果。

```python
result = inference(model_path, img)
```

### 3.1.5 快速开始

以resnet模型为例，执行下述令调用resnet50.q.onnx模型进行图像分类：

```shell
source ~/demo-zoo-venv/bin/activate
cd ~/spacemit_demo/examples/CV/resnet/python
python test_resnet.py
```

`test_resnet.py` 脚本支持参数有：

-  `--model model_path`：指定特定模型路径
- `--image_path image`：指定目标推理图片路径

执行结果如下图：

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="images/classification_3.png">
    <br>
</center>

## 3.2 图像分割

### 3.2.1 简介

图像分割是计算机视觉中的一个关键任务，其目标是将一幅图像划分成多个部分或区域，每个部分通常对应着某个特定的对象或者场景的一部分。图像分割可以被看作是对图像内容的一种详细理解方式，它不仅识别图像中有什么（如分类任务），还指出它们在哪里以及它们的精确边界。

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="images/segmentation_1.png">
    <br>
</center>
### 3.2.2 常见模型

常见的图像分类模型包括FCN，Unet等，进迭时空Demo Zoo提供多种分类模型，详见 [CV模型支持列表](https://active.spacemit.com/doc/RISC-V比赛/03_蓝桥杯比赛产品包/06_Demo%20Zoo#1.-CV模型列表)。

### 3.2.3 图像分割流程 

图像分割的一般流程如下图所示：

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="images/segmentation_2.png">
    <br>
</center>
- **后处理**：在模型推理阶段之后，对模型输出结果进行的一系列操作，目的是优化结果，增强模型输出的准确性、可用性和可解释性。

### 3.2.4 API简介

#### 预处理

图像预处理的API函数如下，`img` 为 `cv2.imread` 的结果。

```python
img = preprocess(img)
```

#### 推理

模型推理API函数如下所示，`model_path` 为具体的模型路径，`img` 为调用预处理后的结果。

```python
outputs = inference(args.model,img)
```

#### 后处理

对推理结果后处理的API函数如下所示，`outputs` 为推理结果。

```python
res = postprocess(outputs)
```

### 3.2.5 快速开始

以FCN模型为例，执行下述令调用fcn_r50.q.onnx模型进行图像分割：

```shell
source ~/demo-zoo-venv/bin/activate
cd ~/spacemit_demo/examples/CV/fcn/pyhton
python test_fcn.py
```

`test_fcn.py` 脚本支持参数有：

-  `--model model_path`：指定特定模型路径
- `--image_path image`：指定目标推理图片路径

执行结果保存在~/spacemit_demo/examples/CV/fcn/data/output.jpg，如图所示。

![image-20250417175539811](images/fcn-run.png)

## 3.3 目标检测

### 3.3.1 简介

目标检测是计算机视觉领域中的一个重要任务，其主要目的是在图像或视频中识别出特定对象的位置及其类别。与图像分类不同，目标检测不仅需要识别图像中存在哪些物体，还需要给出每个物体的具体位置，通常以边界框（bounding box）的形式表示。

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="images/detection_1.png">
    <br>
</center>
### 3.3.2 常见模型

目前比较常用的目标检测模型以YOLO系列为主，进迭时空Demo Zoo中支持的大多也是YOLO系列的模型，详见 [CV模型支持列表](https://active.spacemit.com/doc/RISC-V比赛/03_蓝桥杯比赛产品包/06_Demo%20Zoo#1.-CV模型列表)。

### 3.3.3 目标检测流程 

目标检测的一般流程如下图：

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="images/segmentation_2.png">
    <br>
</center>

### 3.3.4 API简介

#### 预处理

图像预处理的API函数如下，`frame` 为 `cv2.imread` 或者 `cap.read` 的结果

```python
input_tensor = preprocess(frame)
```

#### Detection类

目标检测类实例化后可调用infer函数进行推理，`model_path` 为模型路径，`input_tensor` 为预处理后的结果。

```python
detector = Detection(model_path)
outputs = detector.infer(input_tensor)
```

#### 后处理

推理结果后处理的API函数如下，`output` 为上一步处理的结果，详见 `test_yolov8.py`。

```python
dets = postprocess(frame,output, anchors, offset, conf_threshold=args.conf_threshold)
final_dets = nms(dets,iou_threshold=0.45)
```

### 3.3.5 快速开始

以YOLOv8模型为例，执行下述令调用yolov8n.q.onnx模型进行目标检测：

```shell
source ~/demo-zoo-venv/bin/activate
cd ~/spacemit_demo/examples/CV/yolov8/python
python test_yolov8.py
```

`test_yolov8.py` 脚本支持参数有：

-  `--model model_path`：指定特定模型路径
-  `--image_path image`：指定目标推理图片路径
-  `--use-camera`：打开摄像头

执行结果保存在~/spacemit_demo/examples/CV/yolov8/python/result.jpg，如图所示。

![image-20250417175235350](images/yolov8-run.png)

